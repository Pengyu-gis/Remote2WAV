{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP5z/C4ZU88iVxd91vYZkCe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pengyu-gis/Remote2WAV/blob/main/Im2Wav.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExX3Uzg5EEiW"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/RoySheffer/im2wav.git\n",
        "%cd im2wav\n",
        "\n",
        "# Install dependencies\n",
        "!pip install -r requirements.txt\n",
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directories\n",
        "!mkdir -p pre_trained logs/im2wav_vq logs/im2wav_low logs/im2wav_up\n",
        "\n",
        "# Download checkpoints\n",
        "!gdown 1lCrGsMXqmeKBk-3B3J2jzxNur9olWseb -O /content/im2wav/pre_trained/vqvae.tar\n",
        "!gdown 1v9dmCwrEwkwJhbe2YF3ScM2gjVplSLzt -O /content/im2wav/pre_trained/low.tar\n",
        "!gdown 1UyNBjoxgqBYqA_aYhOu6BHYlkT4CD_M_ -O /content/im2wav/pre_trained/up.tar\n",
        "\n",
        "# Link checkpoints\n",
        "!ln -s /content/im2wav/pre_trained/im2wav_vq.pth.tar logs/im2wav_vq/checkpoint_latest.pth.tar\n",
        "!ln -s /content/im2wav/pre_trained/im2wav_low.pth.tar logs/im2wav_low/checkpoint_latest.pth.tar\n",
        "!ln -s /content/im2wav/pre_trained/im2wav_up.pth.tar logs/im2wav_up/checkpoint_latest.pth.tar"
      ],
      "metadata": {
        "id": "5ADWhz3VFVSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/im2wav')  # Directly add project root to path"
      ],
      "metadata": {
        "id": "9lDC_UmXGdXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from im2wav.im2wav_utils import *"
      ],
      "metadata": {
        "id": "MGM6HSYoGgxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -qq libportaudio2 portaudio19-dev\n",
        "!pip install --force-reinstall sounddevice"
      ],
      "metadata": {
        "id": "q27OoiW9Hjy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y clip  # Remove any existing incorrect installations\n",
        "!pip install git+https://github.com/openai/CLIP.git"
      ],
      "metadata": {
        "id": "3C0deX2hLTLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wav2clip\n",
        "!pip install sounddevice\n",
        "!pip install fire\n",
        "!pip install av"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHrIo_j-GnCZ",
        "outputId": "4ad2986e-333f-4beb-9751-cfd1d86978f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 wav2clip-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/im2wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uoZZhlXIHDl",
        "outputId": "9cb9d5b8-7876-4984-87fc-3a4dc88b58ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/im2wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/im2wav')  # Project root\n",
        "sys.path.append('/content/im2wav/models')  # Models directory"
      ],
      "metadata": {
        "id": "ALhVi57lJWbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!touch /content/im2wav/models/__init__.py\n",
        "!touch /content/im2wav/Data/__init__.py"
      ],
      "metadata": {
        "id": "-p9xg6hZJhh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate CLIP embeddings for your image\n",
        "!python /content/im2wav/Data/preprocess/collect_image_CLIP.py \\\n",
        "  -path_list /content/00903_2.jpg  # Replace with your filename"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bt9-UVGIFsnt",
        "outputId": "fd649928-329e-4365-9211-9be13bc25e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'save_dir': 'image_CLIP', 'path_list': ['/content/00903_2.jpg']}\n",
            "100%|███████████████████████████████████████| 338M/338M [00:05<00:00, 63.8MiB/s]\n",
            "image features class:  00903_2 (1, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/im2wav/models/sample.py \\\n",
        "-bs 2 \\\n",
        "-wav_per_object 2 \\\n",
        "-experiment_name image_CLIP \\\n",
        "-CLIP_dict image_CLIP/CLIP.pickle \\\n",
        "-models im2wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfC5qsXlL34C",
        "outputId": "0caaa167-6c4a-4208-afeb-35a75f3ba03a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'experiment_name': 'image_CLIP', 'save_dir': 'samples', 'model_name': 'my_model', 'vq_cp': None, 'prior_cp': None, 'up_cp': None, 'resultsDir': '', 'bs': 2, 'first': None, 'cfg_s': 3.0, 'wav_per_object': 2, 'p_grid': [0], 'k_grid': [0], 'CLIP_dir': None, 'CLIP_dict': 'image_CLIP/CLIP.pickle', 'models': ['im2wav'], 'hop_fraction': None, 'sample_length': 65536, 'sliding_window_total_sample_length': None}\n",
            "Using cuda True\n",
            "using cuda hps:{'experiment_name': 'image_CLIP', 'save_dir': 'samples', 'model_name': 'im2wav', 'vq_cp': '../pre_trained/vqvae.tar', 'prior_cp': '../pre_trained/low.tar', 'up_cp': '../pre_trained/up.tar', 'resultsDir': 'k_top0_p_top0', 'bs': 2, 'first': None, 'cfg_s': 3.0, 'wav_per_object': 2, 'p_grid': [0], 'k_grid': [0], 'CLIP_dir': None, 'CLIP_dict': 'image_CLIP/CLIP.pickle', 'models': ['im2wav'], 'hop_fraction': None, 'sample_length': 65536, 'sliding_window_total_sample_length': None, 'total_sample_length': 65536, 'num_batches': 1, 'top_k': 0, 'top_p': 0}\n",
            "/content/im2wav/models/make_models.py:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = t.load(restore, map_location=t.device('cpu'))\n",
            "Restored from ../pre_trained/vqvae.tar\n",
            "Restored from ../pre_trained/vqvae.tar\n",
            "0: Loading vqvae in eval mode\n",
            "Restored from ../pre_trained/low.tar\n",
            "Level:1, Cond downsample:None, Raw to tokens:32, Sample length:65536\n",
            "0: Converting to fp16 params\n",
            "Restored from ../pre_trained/low.tar\n",
            "0: Loading prior in eval mode\n",
            "Restored from ../pre_trained/up.tar\n",
            "Conditioning on 1 above level(s)\n",
            "Checkpointing convs\n",
            "Checkpointing convs\n",
            "Level:0, Cond downsample:4, Raw to tokens:8, Sample length:65536\n",
            "0: Converting to fp16 params\n",
            "Restored from ../pre_trained/up.tar\n",
            "0: Loading prior in eval mode\n",
            "im2wav starting from 0 top_k: 0 top_p: 0   --------------------------------------------------------------------\n",
            "required 2 in [0, 2]\n",
            "0.0 30\n",
            "using frames [0, 122] out of the total 1 frames 122.0 =? 1.0\n",
            "Ancestral sampling 2 samples with temp=1.0, top_k=0, top_p=0\n",
            "/content/im2wav/models/prior/conditioners.py:234: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)\n",
            "  mask = t.cuda.FloatTensor(start_emb.shape[0]).uniform_() < cfg_prob\n",
            "100% 2048/2048 [02:55<00:00, 11.66it/s]\n",
            "Ancestral sampling 2 samples with temp=1.0, top_k=0, top_p=0\n",
            "100% 8192/8192 [06:04<00:00, 22.46it/s]\n",
            "finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "import os\n",
        "\n",
        "output_dir = \"/content/im2wav/samples\"\n",
        "audio_files = [f for f in os.listdir(output_dir) if f.endswith(\".wav\")]\n",
        "\n",
        "for f in audio_files:\n",
        "    display(Audio(os.path.join(output_dir, f)))"
      ],
      "metadata": {
        "id": "GpYJNnjFMxvQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}